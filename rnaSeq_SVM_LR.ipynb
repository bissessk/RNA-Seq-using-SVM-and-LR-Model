{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RNA-Seq Using SVM and Logistic Regression**\n",
    " ## Kieran Bissessar (kb2784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNA-seq is a method of detecting gene transcript abundance. For a given sample, the number of sequencing reads matching a specific gene is reported. In this dataset, the normalized RNA-seq counts have been provided for over 20,000 genes from different mutant samples. Our goal is to be able to determine the mutation given a set of values for the different genes ( 20,000+ )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Read in RNA-Seq Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data head :\n",
      "  Unnamed: 0  gene_0    gene_1    gene_2    gene_3     gene_4  gene_5  \\\n",
      "0   sample_0     0.0  2.017209  3.265527  5.478487  10.431999     0.0   \n",
      "1   sample_1     0.0  0.592732  1.588421  7.586157   9.623011     0.0   \n",
      "2   sample_2     0.0  3.511759  4.327199  6.881787   9.870730     0.0   \n",
      "3   sample_3     0.0  3.663618  4.507649  6.659068  10.196184     0.0   \n",
      "4   sample_4     0.0  2.655741  2.821547  6.539454   9.738265     0.0   \n",
      "\n",
      "     gene_6    gene_7  gene_8  ...  gene_20521  gene_20522  gene_20523  \\\n",
      "0  7.175175  0.591871     0.0  ...    4.926711    8.210257    9.723516   \n",
      "1  6.816049  0.000000     0.0  ...    4.593372    7.323865    9.740931   \n",
      "2  6.972130  0.452595     0.0  ...    5.125213    8.127123   10.908640   \n",
      "3  7.843375  0.434882     0.0  ...    6.076566    8.792959   10.141520   \n",
      "4  6.566967  0.360982     0.0  ...    5.996032    8.891425   10.373790   \n",
      "\n",
      "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
      "0    7.220030    9.119813   12.003135    9.650743    8.921326    5.286759   \n",
      "1    6.256586    8.381612   12.674552   10.517059    9.397854    2.094168   \n",
      "2    5.401607    9.911597    9.045255    9.788359   10.090470    1.683023   \n",
      "3    8.942805    9.601208   11.392682    9.694814    9.684365    3.292001   \n",
      "4    7.181162    9.846910   11.922439    9.217749    9.461191    5.110372   \n",
      "\n",
      "   gene_20530  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "\n",
      "[5 rows x 20532 columns]\n",
      "\n",
      "\n",
      "Labels head :\n",
      "  Unnamed: 0 Class\n",
      "0   sample_0  PRAD\n",
      "1   sample_1  LUAD\n",
      "2   sample_2  PRAD\n",
      "3   sample_3  PRAD\n",
      "4   sample_4  BRCA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "\n",
    "data = pd.read_csv(\"data.csv\");\n",
    "print(\"Data head :\");\n",
    "print(data.head());\n",
    "\n",
    "labels = pd.read_csv(\"labels.csv\");\n",
    "print(\"\\n\\nLabels head :\");\n",
    "print(labels.head());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Merge data.csv and labels.csv into a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0 Class  gene_0    gene_1    gene_2    gene_3     gene_4  gene_5  \\\n",
      "0   sample_0  PRAD     0.0  2.017209  3.265527  5.478487  10.431999     0.0   \n",
      "1   sample_1  LUAD     0.0  0.592732  1.588421  7.586157   9.623011     0.0   \n",
      "2   sample_2  PRAD     0.0  3.511759  4.327199  6.881787   9.870730     0.0   \n",
      "3   sample_3  PRAD     0.0  3.663618  4.507649  6.659068  10.196184     0.0   \n",
      "4   sample_4  BRCA     0.0  2.655741  2.821547  6.539454   9.738265     0.0   \n",
      "\n",
      "     gene_6    gene_7  ...  gene_20521  gene_20522  gene_20523  gene_20524  \\\n",
      "0  7.175175  0.591871  ...    4.926711    8.210257    9.723516    7.220030   \n",
      "1  6.816049  0.000000  ...    4.593372    7.323865    9.740931    6.256586   \n",
      "2  6.972130  0.452595  ...    5.125213    8.127123   10.908640    5.401607   \n",
      "3  7.843375  0.434882  ...    6.076566    8.792959   10.141520    8.942805   \n",
      "4  6.566967  0.360982  ...    5.996032    8.891425   10.373790    7.181162   \n",
      "\n",
      "   gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  gene_20530  \n",
      "0    9.119813   12.003135    9.650743    8.921326    5.286759         0.0  \n",
      "1    8.381612   12.674552   10.517059    9.397854    2.094168         0.0  \n",
      "2    9.911597    9.045255    9.788359   10.090470    1.683023         0.0  \n",
      "3    9.601208   11.392682    9.694814    9.684365    3.292001         0.0  \n",
      "4    9.846910   11.922439    9.217749    9.461191    5.110372         0.0  \n",
      "\n",
      "[5 rows x 20533 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(labels,\n",
    "              data,\n",
    "              how = 'inner');\n",
    "\n",
    "print(df.head());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Randomly divide the data into Train and test set in the ratio 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0 Class    gene_0    gene_1    gene_2    gene_3     gene_4  \\\n",
      "364  sample_364  KIRC  0.000000  0.000000  2.275752  6.025051  10.181674   \n",
      "458  sample_458  KIRC  0.757450  1.915330  1.182565  6.282078   8.972058   \n",
      "76    sample_76  BRCA  0.000000  3.195537  2.275156  5.719778   9.145591   \n",
      "64    sample_64  PRAD  0.000000  2.949311  4.597877  7.095460   9.762425   \n",
      "638  sample_638  BRCA  0.000000  3.777693  3.417920  7.031164   9.960924   \n",
      "..          ...   ...       ...       ...       ...       ...        ...   \n",
      "763  sample_763  LUAD  0.000000  4.235061  4.218874  6.542637   8.981995   \n",
      "192  sample_192  LUAD  0.531868  3.755486  1.868963  6.726123  10.859449   \n",
      "629  sample_629  BRCA  0.000000  2.615675  1.855511  7.722616   9.798412   \n",
      "559  sample_559  KIRC  0.000000  2.736930  3.005256  6.358199   8.978988   \n",
      "684  sample_684  PRAD  0.000000  2.387197  4.344992  7.031561   9.868644   \n",
      "\n",
      "     gene_5    gene_6    gene_7  ...  gene_20521  gene_20522  gene_20523  \\\n",
      "364     0.0  6.112777  0.565890  ...    5.402804    7.875964   10.120121   \n",
      "458     0.0  5.440902  0.000000  ...    7.455081    8.825525   10.021993   \n",
      "76      0.0  7.333683  1.192762  ...    6.534924    9.382676    9.893725   \n",
      "64      0.0  6.493412  0.000000  ...    6.066335    9.048356   10.287493   \n",
      "638     0.0  8.119844  0.605020  ...    6.012622    9.200089   10.349337   \n",
      "..      ...       ...       ...  ...         ...         ...         ...   \n",
      "763     0.0  6.571407  0.000000  ...    6.318013    8.775600   10.591485   \n",
      "192     0.0  7.610154  0.000000  ...    4.884266    8.129752    9.938672   \n",
      "629     0.0  6.767575  0.000000  ...    5.255127    8.311212    9.200391   \n",
      "559     0.0  8.225689  1.639695  ...    6.656396    8.255959   10.476351   \n",
      "684     0.0  6.059669  0.000000  ...    5.879000    8.886654    9.937745   \n",
      "\n",
      "     gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
      "364    2.412185    9.498614   12.894869   10.434430    9.048045    7.690501   \n",
      "458    4.769322   10.375094   11.470994   10.853918    9.552183    6.474248   \n",
      "76     7.298759    9.906667   11.913095    9.846816    9.708798    5.412016   \n",
      "64     6.026973   10.008611   10.621622   10.727623   10.216661    3.424841   \n",
      "638    7.662690   10.048705   11.122394   10.646865   10.228614    5.134455   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "763    1.459799   10.050706   10.911017   10.932503    9.151466    4.431035   \n",
      "192    6.847158    9.011046   11.632282    9.872284    9.073266    9.106317   \n",
      "629    7.574147    9.427313   12.247043    9.690719   10.272688    3.041138   \n",
      "559    3.982921    9.979982   11.819632   10.402042    9.403564    5.191721   \n",
      "684    3.871489    9.444742   11.083486    9.577850    9.307531    5.827441   \n",
      "\n",
      "     gene_20530  \n",
      "364    0.000000  \n",
      "458    0.000000  \n",
      "76     0.000000  \n",
      "64     0.000000  \n",
      "638    0.000000  \n",
      "..          ...  \n",
      "763    0.000000  \n",
      "192    0.000000  \n",
      "629    1.841007  \n",
      "559    0.000000  \n",
      "684    0.000000  \n",
      "\n",
      "[640 rows x 20533 columns]\n",
      "     Unnamed: 0 Class  gene_0    gene_1    gene_2    gene_3     gene_4  \\\n",
      "8      sample_8  BRCA     0.0  3.992125  2.772730  6.546692  10.488252   \n",
      "253  sample_253  BRCA     0.0  4.032383  3.544226  7.015382   9.726639   \n",
      "85    sample_85  PRAD     0.0  4.393910  5.578099  6.304062   9.335779   \n",
      "406  sample_406  BRCA     0.0  0.000000  2.532342  7.111699  11.355621   \n",
      "14    sample_14  BRCA     0.0  1.964842  2.183010  6.596832  10.248141   \n",
      "..          ...   ...     ...       ...       ...       ...        ...   \n",
      "48    sample_48  BRCA     0.0  3.768449  2.736172  6.698538  10.002281   \n",
      "210  sample_210  LUAD     0.0  2.352504  2.541366  6.823495  10.259614   \n",
      "338  sample_338  PRAD     0.0  2.889532  2.989956  6.999470  10.571174   \n",
      "473  sample_473  COAD     0.0  2.676696  0.000000  7.318823  10.005737   \n",
      "202  sample_202  KIRC     0.0  3.724989  2.398733  6.328896   9.768034   \n",
      "\n",
      "     gene_5    gene_6    gene_7  ...  gene_20521  gene_20522  gene_20523  \\\n",
      "8       0.0  7.690222  0.352307  ...    6.721974    9.597533    9.763753   \n",
      "253     0.0  9.417450  1.493647  ...    6.214214    8.917208   10.106026   \n",
      "85      0.0  7.994659  0.471031  ...    6.099455    8.889836   10.173740   \n",
      "406     0.0  9.025710  0.751549  ...    4.282195    7.572526   10.384482   \n",
      "14      0.0  7.087251  0.441483  ...    6.078847   10.829588   10.404567   \n",
      "..      ...       ...       ...  ...         ...         ...         ...   \n",
      "48      0.0  7.708953  0.768502  ...    7.128644   10.141775   10.382408   \n",
      "210     0.0  6.326269  0.000000  ...    5.198270    7.882233    8.963838   \n",
      "338     0.0  7.422317  0.000000  ...    5.247259    8.600983    9.878005   \n",
      "473     0.0  7.670437  0.535555  ...    6.048234    8.452254    9.713809   \n",
      "202     0.0  7.688523  0.335483  ...    6.973152    9.234736   11.000465   \n",
      "\n",
      "     gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
      "8      7.933278   10.952880   12.498919   10.389954   10.390255    7.828321   \n",
      "253    7.517299   10.231905   12.161988   10.353037   10.243483    7.925590   \n",
      "85     6.863492    9.724811   11.775779   10.652388    9.644963    7.692037   \n",
      "406    7.556897    8.915655   12.882221   10.008134    9.134994    8.329124   \n",
      "14     6.588536    8.952596   10.461725   10.582857    9.488141    3.261967   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "48     7.328136    9.752237   11.369843    8.097774    9.028680    4.489042   \n",
      "210    5.740264    9.977638   12.356075    9.423801    9.575008    5.176171   \n",
      "338    7.987054    9.978382   11.302685    9.597213    9.534645    3.736334   \n",
      "473    0.535555    9.133173   12.899708   10.082508    8.774468    6.058000   \n",
      "202    6.163883    9.958519   11.450216   10.824991    8.954650    4.633908   \n",
      "\n",
      "     gene_20530  \n",
      "8      0.000000  \n",
      "253    0.000000  \n",
      "85     0.471031  \n",
      "406    0.000000  \n",
      "14     0.000000  \n",
      "..          ...  \n",
      "48     0.000000  \n",
      "210    0.000000  \n",
      "338    0.000000  \n",
      "473    0.000000  \n",
      "202    0.000000  \n",
      "\n",
      "[161 rows x 20533 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split;\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data, \n",
    "#                                                    labels, \n",
    "#                                                    test_size=0.2, \n",
    "#                                                    random_state=0);\n",
    "\n",
    "data_train , data_test = train_test_split(df, test_size = 0.2, random_state = 0);\n",
    "print(data_train)\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Distribution Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install seaborn\n",
    "import seaborn as sns;\n",
    "sns.set(color_codes = True);\n",
    "\n",
    "sns.distplot(data_train.iloc[:,2:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler;\n",
    "sc = StandardScaler()\n",
    "sc.fit(data_train.iloc[:,2:])\n",
    "data_train_std = sc.transform(data_train.iloc[:,2:])\n",
    "data_test_std = sc.transform(data_test.iloc[:,2:])\n",
    "\n",
    "sns.distplot(data_train_std);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 SVM Classifier for all combinations of 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: ['BRCA' 'COAD' 'KIRC' 'LUAD' 'PRAD']\n",
      "\n",
      "COMBINATIONS :\n",
      "\t 1.  BRCA   COAD\n",
      "\t 2.  BRCA   KIRC\n",
      "\t 3.  BRCA   LUAD\n",
      "\t 4.  BRCA   PRAD\n",
      "\t 5.  COAD   KIRC\n",
      "\t 6.  COAD   LUAD\n",
      "\t 7.  COAD   PRAD\n",
      "\t 8.  KIRC   LUAD\n",
      "\t 9.  KIRC   PRAD\n",
      "\t10.  LUAD   PRAD\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "print('Class labels:', np.unique(labels.iloc[:,1:]))\n",
    "class_lst = np.unique(labels.iloc[:,1:]);\n",
    "\n",
    "print(\"\\nCOMBINATIONS :\",);\n",
    "print(\"\\t 1. \", class_lst[0],\" \",class_lst[1]);\n",
    "print(\"\\t 2. \", class_lst[0],\" \",class_lst[2]);\n",
    "print(\"\\t 3. \", class_lst[0],\" \",class_lst[3]);\n",
    "print(\"\\t 4. \", class_lst[0],\" \",class_lst[4]);\n",
    "print(\"\\t 5. \", class_lst[1],\" \",class_lst[2]);\n",
    "print(\"\\t 6. \", class_lst[1],\" \",class_lst[3]);\n",
    "print(\"\\t 7. \", class_lst[1],\" \",class_lst[4]);\n",
    "print(\"\\t 8. \", class_lst[2],\" \",class_lst[3]);\n",
    "print(\"\\t 9. \", class_lst[2],\" \",class_lst[4]);\n",
    "print(\"\\t10. \", class_lst[3],\" \",class_lst[4]);\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca_bool = (data_train['Class'] == 'BRCA');\n",
    "coad_bool = (data_train['Class'] == 'COAD');\n",
    "kirc_bool = (data_train['Class'] == 'KIRC');\n",
    "luad_bool = (data_train['Class'] == 'LUAD');\n",
    "prad_bool = (data_train['Class'] == 'PRAD');\n",
    "\n",
    "data_train_BRCA = data_train_std[brca_bool];\n",
    "data_train_COAD = data_train_std[coad_bool];\n",
    "data_train_KIRC = data_train_std[kirc_bool];\n",
    "data_train_LUAD = data_train_std[luad_bool];\n",
    "data_train_PRAD = data_train_std[prad_bool];\n",
    "\n",
    "y_train_BRCA = data_train.iloc[:,1][brca_bool];\n",
    "y_train_COAD = data_train.iloc[:,1][coad_bool];\n",
    "y_train_KIRC = data_train.iloc[:,1][kirc_bool];\n",
    "y_train_LUAD = data_train.iloc[:,1][luad_bool];\n",
    "y_train_PRAD = data_train.iloc[:,1][prad_bool];\n",
    "\n",
    "\n",
    "data_train01 = np.vstack((data_train_BRCA , data_train_COAD))\n",
    "data_train02 = np.vstack((data_train_BRCA , data_train_KIRC))\n",
    "data_train03 = np.vstack((data_train_BRCA , data_train_LUAD))\n",
    "data_train04 = np.vstack((data_train_BRCA , data_train_PRAD))\n",
    "data_train12 = np.vstack((data_train_COAD , data_train_KIRC))\n",
    "data_train13 = np.vstack((data_train_COAD , data_train_LUAD))\n",
    "data_train14 = np.vstack((data_train_COAD , data_train_PRAD))\n",
    "data_train23 = np.vstack((data_train_KIRC , data_train_LUAD))\n",
    "data_train24 = np.vstack((data_train_KIRC , data_train_PRAD))\n",
    "data_train34 = np.vstack((data_train_LUAD , data_train_PRAD))\n",
    "\n",
    "y_train01 = pd.concat([y_train_BRCA , y_train_COAD])\n",
    "y_train02 = pd.concat([y_train_BRCA , y_train_KIRC])\n",
    "y_train03 = pd.concat([y_train_BRCA , y_train_LUAD])\n",
    "y_train04 = pd.concat([y_train_BRCA , y_train_PRAD])\n",
    "y_train12 = pd.concat([y_train_COAD , y_train_KIRC])\n",
    "y_train13 = pd.concat([y_train_COAD , y_train_LUAD])\n",
    "y_train14 = pd.concat([y_train_COAD , y_train_PRAD])\n",
    "y_train23 = pd.concat([y_train_KIRC , y_train_LUAD])\n",
    "y_train24 = pd.concat([y_train_KIRC , y_train_PRAD])\n",
    "y_train34 = pd.concat([y_train_LUAD , y_train_PRAD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca_bool_test = (data_test['Class'] == 'BRCA');\n",
    "coad_bool_test = (data_test['Class'] == 'COAD');\n",
    "kirc_bool_test = (data_test['Class'] == 'KIRC');\n",
    "luad_bool_test = (data_test['Class'] == 'LUAD');\n",
    "prad_bool_test = (data_test['Class'] == 'PRAD');\n",
    "\n",
    "data_test_BRCA = data_test_std[brca_bool_test];\n",
    "data_test_COAD = data_test_std[coad_bool_test];\n",
    "data_test_KIRC = data_test_std[kirc_bool_test];\n",
    "data_test_LUAD = data_test_std[luad_bool_test];\n",
    "data_test_PRAD = data_test_std[prad_bool_test];\n",
    "\n",
    "y_test_BRCA = data_test.iloc[:,1][brca_bool_test];\n",
    "y_test_COAD = data_test.iloc[:,1][coad_bool_test];\n",
    "y_test_KIRC = data_test.iloc[:,1][kirc_bool_test];\n",
    "y_test_LUAD = data_test.iloc[:,1][luad_bool_test];\n",
    "y_test_PRAD = data_test.iloc[:,1][prad_bool_test];\n",
    "\n",
    "data_test01 = np.vstack((data_test_BRCA , data_test_COAD))\n",
    "data_test02 = np.vstack((data_test_BRCA , data_test_KIRC))\n",
    "data_test03 = np.vstack((data_test_BRCA , data_test_LUAD))\n",
    "data_test04 = np.vstack((data_test_BRCA , data_test_PRAD))\n",
    "data_test12 = np.vstack((data_test_COAD , data_test_KIRC))\n",
    "data_test13 = np.vstack((data_test_COAD , data_test_LUAD))\n",
    "data_test14 = np.vstack((data_test_COAD , data_test_PRAD))\n",
    "data_test23 = np.vstack((data_test_KIRC , data_test_LUAD))\n",
    "data_test24 = np.vstack((data_test_KIRC , data_test_PRAD))\n",
    "data_test34 = np.vstack((data_test_LUAD , data_test_PRAD))\n",
    "\n",
    "y_test01 = pd.concat([y_test_BRCA , y_test_COAD])\n",
    "y_test02 = pd.concat([y_test_BRCA , y_test_KIRC])\n",
    "y_test03 = pd.concat([y_test_BRCA , y_test_LUAD])\n",
    "y_test04 = pd.concat([y_test_BRCA , y_test_PRAD])\n",
    "y_test12 = pd.concat([y_test_COAD , y_test_KIRC])\n",
    "y_test13 = pd.concat([y_test_COAD , y_test_LUAD])\n",
    "y_test14 = pd.concat([y_test_COAD , y_test_PRAD])\n",
    "y_test23 = pd.concat([y_test_KIRC , y_test_LUAD])\n",
    "y_test24 = pd.concat([y_test_KIRC , y_test_PRAD])\n",
    "y_test34 = pd.concat([y_test_LUAD , y_test_PRAD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC;\n",
    "\n",
    "svm01 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm01.fit(data_train01, y_train01);\n",
    "\n",
    "svm02 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm02.fit(data_train02, y_train02);\n",
    "\n",
    "svm03 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm03.fit(data_train03 , y_train03);\n",
    "\n",
    "svm04 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm04.fit(data_train04, y_train04);\n",
    "\n",
    "svm12 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm12.fit(data_train12, y_train12);\n",
    "\n",
    "svm13 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm13.fit(data_train13, y_train13);\n",
    "\n",
    "svm14 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm14.fit(data_train14, y_train14);\n",
    "\n",
    "svm23 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm23.fit(data_train23, y_train23);\n",
    "\n",
    "svm24 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm24.fit(data_train24, y_train24);\n",
    "\n",
    "svm34 = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm34.fit(data_train34, y_train34);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Weight Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20680191 -2.53389798 -0.79848496 ... -0.95178507  1.05385861\n",
      "  -0.24865145]\n",
      " [ 4.86041305 -0.92157257 -1.84423579 ... -0.0571117   0.46829036\n",
      "  -0.24865145]\n",
      " [-0.20680191  0.1561062  -0.79905507 ...  0.22082625 -0.04312397\n",
      "  -0.24865145]\n",
      " ...\n",
      " [-0.20680191 -0.33202135 -1.20049037 ...  1.2215407  -1.18458949\n",
      "   4.47158555]\n",
      " [-0.20680191 -0.22994944 -0.10063572 ... -0.32086032 -0.14918577\n",
      "  -0.24865145]\n",
      " [-0.20680191 -0.52435437  1.18096544 ... -0.49128611  0.15688328\n",
      "  -0.24865145]]\n",
      "Weight Matrix :\n",
      "[[ 1.44299134e-05 -5.51741390e-05 -1.84568842e-05 ...  1.72470756e-04\n",
      "   2.87649548e-04 -3.39748575e-05]\n",
      " [-5.59770747e-05  2.10751563e-04  1.27160972e-04 ...  7.29020950e-05\n",
      "   2.67553136e-04 -5.50317810e-05]\n",
      " [-1.27341542e-04 -3.86050467e-05 -1.84153614e-04 ...  1.03047394e-04\n",
      "   5.68588850e-04 -1.36766825e-04]\n",
      " ...\n",
      " [ 3.38803038e-05 -3.33920081e-04 -2.46955602e-04 ...  1.06879172e-05\n",
      "  -2.54068406e-05  6.07309905e-05]\n",
      " [-4.11079229e-05 -1.48046111e-04 -2.86747460e-04 ... -3.46494229e-05\n",
      "   1.94180247e-05  1.31348788e-04]\n",
      " [ 5.67350412e-05  1.09058244e-04 -6.29209310e-05 ... -1.57114751e-04\n",
      "  -1.23693153e-04  1.41735962e-04]]\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "Xw = np.array(data_train_std);\n",
    "print(Xw);\n",
    "#%matplotlib inline\n",
    "svm_w = SVC(kernel = \"linear\", C=1e10, random_state = 0);\n",
    "svm_w.fit(Xw, data_train.iloc[:,1]);\n",
    "W=svm_w.coef_;\n",
    "#W=W.flatten();\n",
    "print(\"Weight Matrix :\");\n",
    "print(W)\n",
    "#plt.stem(W, use_line_collection = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Accuracy on train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "0.9891304347826086\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score;\n",
    "y_pred_test01 = svm01.predict(data_test01)\n",
    "print(accuracy_score(y_test01, y_pred_test01))\n",
    "y_pred_train01 = svm01.predict(data_train01)\n",
    "print(accuracy_score(y_train01, y_pred_train01))\n",
    "print();\n",
    "\n",
    "y_pred_test02 = svm02.predict(data_test02)\n",
    "print(accuracy_score(y_test02, y_pred_test02))\n",
    "y_pred_train02 = svm02.predict(data_train02)\n",
    "print(accuracy_score(y_train02, y_pred_train02))\n",
    "print();\n",
    "\n",
    "y_pred_test03 = svm03.predict(data_test03)\n",
    "print(accuracy_score(y_test03, y_pred_test03))\n",
    "y_pred_train03 = svm03.predict(data_train03)\n",
    "print(accuracy_score(y_train03, y_pred_train03))\n",
    "print();\n",
    "\n",
    "y_pred_test04 = svm04.predict(data_test04)\n",
    "print(accuracy_score(y_test04, y_pred_test04))\n",
    "y_pred_train04 = svm04.predict(data_train04)\n",
    "print(accuracy_score(y_train04, y_pred_train04))\n",
    "print();\n",
    "\n",
    "y_pred_test12 = svm12.predict(data_test12)\n",
    "print(accuracy_score(y_test12, y_pred_test12))\n",
    "y_pred_train12 = svm12.predict(data_train12)\n",
    "print(accuracy_score(y_train12, y_pred_train12))\n",
    "print();\n",
    "\n",
    "y_pred_test13 = svm13.predict(data_test13)\n",
    "print(accuracy_score(y_test13, y_pred_test13))\n",
    "y_pred_train13 = svm13.predict(data_train13)\n",
    "print(accuracy_score(y_train13, y_pred_train13))\n",
    "print();\n",
    "\n",
    "y_pred_test14 = svm14.predict(data_test14)\n",
    "print(accuracy_score(y_test14, y_pred_test14))\n",
    "y_pred_train14 = svm14.predict(data_train14)\n",
    "print(accuracy_score(y_train14, y_pred_train14))\n",
    "print();\n",
    "\n",
    "y_pred_test23 = svm23.predict(data_test23)\n",
    "print(accuracy_score(y_test23, y_pred_test23))\n",
    "y_pred_train23 = svm23.predict(data_train23)\n",
    "print(accuracy_score(y_train23, y_pred_train23))\n",
    "print();\n",
    "\n",
    "y_pred_test24 = svm24.predict(data_test24)\n",
    "print(accuracy_score(y_test24, y_pred_test24))\n",
    "y_pred_train24 = svm24.predict(data_train24)\n",
    "print(accuracy_score(y_train24, y_pred_train24))\n",
    "print();\n",
    "\n",
    "y_pred_test34 = svm34.predict(data_test34)\n",
    "print(accuracy_score(y_test34, y_pred_test34))\n",
    "y_pred_train34 = svm34.predict(data_train34)\n",
    "print(accuracy_score(y_train34, y_pred_train34))\n",
    "print();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the accuraccies seem to be one except for the test for scenario 04 (BRCA PRAD). This happens whether I change the kernel or the C. The train accuracy is the accuracy of a model on examples it was constructed on. The test accuracy is the accuracy of a model on examples it hasn't seen. The test and train accuracies are the same here. It was read that in confusion matrices that a large difference in accuracies in the train and test data would suggest overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 SVM classifier to predict all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364    KIRC\n",
      "458    KIRC\n",
      "76     BRCA\n",
      "64     PRAD\n",
      "638    BRCA\n",
      "       ... \n",
      "763    LUAD\n",
      "192    LUAD\n",
      "629    BRCA\n",
      "559    KIRC\n",
      "684    PRAD\n",
      "Name: Class, Length: 640, dtype: object\n",
      "0.9937888198757764\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel = \"rbf\", C = 1.0, random_state = 0);\n",
    "svm.fit(data_train_std, data_train.iloc[:,1]);\n",
    "print(data_train.iloc[:,1])\n",
    "\n",
    "y_pred_test = svm.predict(data_test_std,)\n",
    "print(accuracy_score(data_test.iloc[:,1], y_pred_test))\n",
    "y_pred_train = svm.predict(data_train_std,)\n",
    "print(accuracy_score(data_train.iloc[:,1], y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Tuning SVM model with various parameters (kernel, regularization (c) , GAMMA, and margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9937888198757764\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.9937888198757764\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## CHANGING C\n",
    "svm_m = SVC(kernel = \"rbf\", C = 1000, random_state = 0);\n",
    "svm_m.fit(data_train_std, data_train.iloc[:,1]);\n",
    "\n",
    "y_pred_test = svm_m.predict(data_test_std,)\n",
    "print(accuracy_score(data_test.iloc[:,1], y_pred_test))\n",
    "y_pred_train = svm_m.predict(data_train_std,)\n",
    "print(accuracy_score(data_train.iloc[:,1], y_pred_train))\n",
    "\n",
    "## CHANGING KERNEL\n",
    "svm_m = SVC(kernel = 'sigmoid', C = 1.0, random_state = 0); # linear also gives 1\n",
    "svm_m.fit(data_train_std, data_train.iloc[:,1]);\n",
    "\n",
    "y_pred_test = svm_m.predict(data_test_std,)\n",
    "print(accuracy_score(data_test.iloc[:,1], y_pred_test))\n",
    "y_pred_train = svm_m.predict(data_train_std,)\n",
    "print(accuracy_score(data_train.iloc[:,1], y_pred_train))\n",
    "\n",
    "## CHANGING GAMMA\n",
    "svm_m = SVC(kernel = \"rbf\", C = 1.0, random_state = 0, gamma = 'auto');\n",
    "svm_m.fit(data_train_std, data_train.iloc[:,1]);\n",
    "\n",
    "y_pred_test = svm_m.predict(data_test_std,)\n",
    "print(accuracy_score(data_test.iloc[:,1], y_pred_test))\n",
    "y_pred_train = svm_m.predict(data_train_std,)\n",
    "print(accuracy_score(data_train.iloc[:,1], y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies still seem high. If anything, a very high c value and implementing gamma seem to slightly lower the accuracy of the test subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Logistic regression model (L1 regularization) comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty = 'l1', solver = \"liblinear\", C = 1.0, random_state = 0);\n",
    "lr.fit(data_train_std, data_train.iloc[:,1]);\n",
    "\n",
    "y_hat = lr.predict(data_train_std);\n",
    "accuracy = np.mean(y_hat == data_train.iloc[:,1])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear logistic regression and SVMs usually get similar results.\n",
    "\n",
    "LR tries to maximize the conditional likelihoods of the training data, which makes it more prone to outliers than SVMs.\n",
    "\n",
    "SVMs cares more about the points that are closest to the decision boundary (support vectors). \n",
    "\n",
    "LR is advantagous in that it is a simpler model - making it easier to implement. LR models can also be easily updated making it better to work with streaming data.\n",
    "\n",
    "It was also learned that SVM works well with unstructured and semi-structured data like text and images while logistic regression works with already identified independent variables. SVM is based on geometrical properties of the data while logistic regression is based on statistical approaches.\n",
    "For this reason, LR might perform better than SVM in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Weight comparison of SVM model and L1 regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm weight matrix :\n",
      "[[ 1.44299134e-05 -5.51741390e-05 -1.84568842e-05 ...  1.72470756e-04\n",
      "   2.87649548e-04 -3.39748575e-05]\n",
      " [-5.59770747e-05  2.10751563e-04  1.27160972e-04 ...  7.29020950e-05\n",
      "   2.67553136e-04 -5.50317810e-05]\n",
      " [-1.27341542e-04 -3.86050467e-05 -1.84153614e-04 ...  1.03047394e-04\n",
      "   5.68588850e-04 -1.36766825e-04]\n",
      " ...\n",
      " [ 3.38803038e-05 -3.33920081e-04 -2.46955602e-04 ...  1.06879172e-05\n",
      "  -2.54068406e-05  6.07309905e-05]\n",
      " [-4.11079229e-05 -1.48046111e-04 -2.86747460e-04 ... -3.46494229e-05\n",
      "   1.94180247e-05  1.31348788e-04]\n",
      " [ 5.67350412e-05  1.09058244e-04 -6.29209310e-05 ... -1.57114751e-04\n",
      "  -1.23693153e-04  1.41735962e-04]]\n",
      "\n",
      " [[-0.20680191 -2.53389798 -0.79848496 ... -0.95178507  1.05385861\n",
      "  -0.24865145]\n",
      " [ 4.86041305 -0.92157257 -1.84423579 ... -0.0571117   0.46829036\n",
      "  -0.24865145]\n",
      " [-0.20680191  0.1561062  -0.79905507 ...  0.22082625 -0.04312397\n",
      "  -0.24865145]\n",
      " ...\n",
      " [-0.20680191 -0.33202135 -1.20049037 ...  1.2215407  -1.18458949\n",
      "   4.47158555]\n",
      " [-0.20680191 -0.22994944 -0.10063572 ... -0.32086032 -0.14918577\n",
      "  -0.24865145]\n",
      " [-0.20680191 -0.52435437  1.18096544 ... -0.49128611  0.15688328\n",
      "  -0.24865145]] \n",
      "\n",
      "LR weight matrix :\n",
      "[[-1.82601009e-03 -2.44419618e-03 -3.26493456e-03 ...  3.13353305e-03\n",
      "   5.86462485e-03  3.79328644e-05]\n",
      " [-1.95478396e-04  1.16276628e-03 -1.69272292e-05 ... -1.47393276e-03\n",
      "  -2.04237389e-03 -4.10379323e-04]\n",
      " [ 1.01160109e-03 -3.13023277e-03 -3.66800229e-03 ... -1.12407417e-03\n",
      "  -1.37231733e-03  9.01280857e-04]\n",
      " [ 8.18241630e-04  2.06218712e-03  2.35913930e-03 ... -1.66651635e-03\n",
      "  -3.18593978e-03  6.15624041e-04]\n",
      " [ 1.91645768e-04  2.34947556e-03  4.59072477e-03 ...  1.13099023e-03\n",
      "   7.36006148e-04 -1.14445844e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"svm weight matrix :\")\n",
    "print(W);\n",
    "#import matplotlib.pyplot as plt\n",
    "Xw = np.array(data_train_std);\n",
    "print(\"\\n\", Xw, \"\\n\");\n",
    "#%matplotlib inline\n",
    "logreg_w = LogisticRegression(C=1e10);\n",
    "logreg_w.fit(Xw, data_train.iloc[:,1]);\n",
    "W2=logreg_w.coef_;\n",
    "#W2=W2.flatten();\n",
    "print(\"LR weight matrix :\")\n",
    "print(W2)\n",
    "#plt.stem(W, use_line_collection = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the weights of the svm and the LR for all of the classes, it can be seen that the weights for the LR model is higher (abs value). This suggests that the labels contribute more\n",
    "heavily in the LR model than the svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
